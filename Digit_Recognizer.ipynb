{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bb81ef9-5f61-46ae-90e9-5bc863552797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(\"HELLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06027e80-4ee6-41b9-8df6-9351d076f82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, datasets, preprocessing\n",
    "\n",
    "training_data = pd.read_csv('/home/pakhandi101/Downloads/digit-recognizer/train.csv')\n",
    "x_train = training_data.iloc[:, 1:].values\n",
    "y_train = training_data.iloc[:, 0].values\n",
    "# x_train = x_train.astype('float32') / 255\n",
    "# y_train = y_train.astype('int')\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "fig, axes = plt.subplots(1, 8, figsize=(16, 2))\n",
    "for i, ax in enumerate(axes):\n",
    "   \n",
    "    ax.imshow((x_train[i]).reshape(28, 28), cmap='gray')\n",
    "    ax.axis('off')\n",
    "   \n",
    "    ax.set_title(f'Label: {int(y_train[i])}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b182f1e-0b8f-4c6f-92e0-62aab4efa6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pakhandi101/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pakhandi101/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 50ms/step - accuracy: 0.6504 - loss: 1.2022 - val_accuracy: 0.9785 - val_loss: 0.0720\n",
      "Epoch 2/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 49ms/step - accuracy: 0.9178 - loss: 0.2600 - val_accuracy: 0.9839 - val_loss: 0.0515\n",
      "Epoch 3/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 49ms/step - accuracy: 0.9404 - loss: 0.1897 - val_accuracy: 0.9863 - val_loss: 0.0445\n",
      "Epoch 4/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 49ms/step - accuracy: 0.9512 - loss: 0.1621 - val_accuracy: 0.9894 - val_loss: 0.0365\n",
      "Epoch 5/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 49ms/step - accuracy: 0.9562 - loss: 0.1398 - val_accuracy: 0.9911 - val_loss: 0.0300\n",
      "Epoch 6/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 52ms/step - accuracy: 0.9624 - loss: 0.1222 - val_accuracy: 0.9920 - val_loss: 0.0263\n",
      "Epoch 7/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 52ms/step - accuracy: 0.9655 - loss: 0.1090 - val_accuracy: 0.9910 - val_loss: 0.0287\n",
      "Epoch 8/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 52ms/step - accuracy: 0.9666 - loss: 0.1072 - val_accuracy: 0.9906 - val_loss: 0.0277\n",
      "Epoch 9/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 50ms/step - accuracy: 0.9696 - loss: 0.0994 - val_accuracy: 0.9925 - val_loss: 0.0226\n",
      "Epoch 10/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 52ms/step - accuracy: 0.9705 - loss: 0.1034 - val_accuracy: 0.9902 - val_loss: 0.0287\n",
      "Epoch 11/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 51ms/step - accuracy: 0.9696 - loss: 0.0979 - val_accuracy: 0.9910 - val_loss: 0.0280\n",
      "Epoch 12/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 49ms/step - accuracy: 0.9724 - loss: 0.0919 - val_accuracy: 0.9920 - val_loss: 0.0269\n",
      "Epoch 13/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 49ms/step - accuracy: 0.9762 - loss: 0.0764 - val_accuracy: 0.9927 - val_loss: 0.0243\n",
      "Epoch 14/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 52ms/step - accuracy: 0.9741 - loss: 0.0830 - val_accuracy: 0.9920 - val_loss: 0.0250\n",
      "Epoch 15/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 53ms/step - accuracy: 0.9744 - loss: 0.0794 - val_accuracy: 0.9920 - val_loss: 0.0244\n",
      "Epoch 16/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 49ms/step - accuracy: 0.9772 - loss: 0.0776 - val_accuracy: 0.9935 - val_loss: 0.0199\n",
      "Epoch 17/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 51ms/step - accuracy: 0.9753 - loss: 0.0807 - val_accuracy: 0.9929 - val_loss: 0.0244\n",
      "Epoch 18/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 58ms/step - accuracy: 0.9767 - loss: 0.0761 - val_accuracy: 0.9931 - val_loss: 0.0227\n",
      "Epoch 19/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 53ms/step - accuracy: 0.9800 - loss: 0.0678 - val_accuracy: 0.9938 - val_loss: 0.0191\n",
      "Epoch 20/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 55ms/step - accuracy: 0.9784 - loss: 0.0683 - val_accuracy: 0.9921 - val_loss: 0.0243\n",
      "Epoch 21/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 51ms/step - accuracy: 0.9788 - loss: 0.0687 - val_accuracy: 0.9935 - val_loss: 0.0204\n",
      "Epoch 22/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 61ms/step - accuracy: 0.9776 - loss: 0.0734 - val_accuracy: 0.9923 - val_loss: 0.0232\n",
      "Epoch 23/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 57ms/step - accuracy: 0.9805 - loss: 0.0632 - val_accuracy: 0.9931 - val_loss: 0.0219\n",
      "Epoch 24/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 55ms/step - accuracy: 0.9805 - loss: 0.0643 - val_accuracy: 0.9933 - val_loss: 0.0224\n",
      "Epoch 25/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 52ms/step - accuracy: 0.9802 - loss: 0.0683 - val_accuracy: 0.9930 - val_loss: 0.0220\n",
      "Epoch 26/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 54ms/step - accuracy: 0.9808 - loss: 0.0615 - val_accuracy: 0.9942 - val_loss: 0.0178\n",
      "Epoch 27/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 52ms/step - accuracy: 0.9818 - loss: 0.0602 - val_accuracy: 0.9938 - val_loss: 0.0183\n",
      "Epoch 28/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 52ms/step - accuracy: 0.9822 - loss: 0.0604 - val_accuracy: 0.9929 - val_loss: 0.0199\n",
      "Epoch 29/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 53ms/step - accuracy: 0.9824 - loss: 0.0605 - val_accuracy: 0.9927 - val_loss: 0.0230\n",
      "Epoch 30/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 50ms/step - accuracy: 0.9828 - loss: 0.0566 - val_accuracy: 0.9944 - val_loss: 0.0191\n",
      "Epoch 31/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 50ms/step - accuracy: 0.9807 - loss: 0.0610 - val_accuracy: 0.9945 - val_loss: 0.0176\n",
      "Epoch 32/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 50ms/step - accuracy: 0.9831 - loss: 0.0529 - val_accuracy: 0.9940 - val_loss: 0.0191\n",
      "Epoch 33/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 50ms/step - accuracy: 0.9822 - loss: 0.0535 - val_accuracy: 0.9936 - val_loss: 0.0202\n",
      "Epoch 34/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 50ms/step - accuracy: 0.9817 - loss: 0.0628 - val_accuracy: 0.9943 - val_loss: 0.0168\n",
      "Epoch 35/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 50ms/step - accuracy: 0.9835 - loss: 0.0561 - val_accuracy: 0.9943 - val_loss: 0.0187\n",
      "Epoch 36/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 50ms/step - accuracy: 0.9838 - loss: 0.0493 - val_accuracy: 0.9940 - val_loss: 0.0190\n",
      "Epoch 37/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 50ms/step - accuracy: 0.9818 - loss: 0.0563 - val_accuracy: 0.9933 - val_loss: 0.0187\n",
      "Epoch 38/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 50ms/step - accuracy: 0.9840 - loss: 0.0542 - val_accuracy: 0.9943 - val_loss: 0.0179\n",
      "Epoch 39/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 50ms/step - accuracy: 0.9835 - loss: 0.0540 - val_accuracy: 0.9943 - val_loss: 0.0160\n",
      "Epoch 40/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 51ms/step - accuracy: 0.9839 - loss: 0.0519 - val_accuracy: 0.9932 - val_loss: 0.0187\n",
      "Epoch 41/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 49ms/step - accuracy: 0.9837 - loss: 0.0513 - val_accuracy: 0.9939 - val_loss: 0.0150\n",
      "Epoch 42/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9844 - loss: 0.0506 - val_accuracy: 0.9950 - val_loss: 0.0157\n",
      "Epoch 43/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9852 - loss: 0.0485 - val_accuracy: 0.9946 - val_loss: 0.0178\n",
      "Epoch 44/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9846 - loss: 0.0514 - val_accuracy: 0.9944 - val_loss: 0.0183\n",
      "Epoch 45/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9848 - loss: 0.0513 - val_accuracy: 0.9940 - val_loss: 0.0181\n",
      "Epoch 46/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9864 - loss: 0.0446 - val_accuracy: 0.9937 - val_loss: 0.0178\n",
      "Epoch 47/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9835 - loss: 0.0502 - val_accuracy: 0.9946 - val_loss: 0.0182\n",
      "Epoch 48/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9856 - loss: 0.0449 - val_accuracy: 0.9945 - val_loss: 0.0169\n",
      "Epoch 49/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9845 - loss: 0.0508 - val_accuracy: 0.9951 - val_loss: 0.0173\n",
      "Epoch 50/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9845 - loss: 0.0519 - val_accuracy: 0.9952 - val_loss: 0.0163\n",
      "Epoch 51/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9847 - loss: 0.0465 - val_accuracy: 0.9948 - val_loss: 0.0180\n",
      "Epoch 52/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9866 - loss: 0.0465 - val_accuracy: 0.9944 - val_loss: 0.0174\n",
      "Epoch 53/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9848 - loss: 0.0496 - val_accuracy: 0.9949 - val_loss: 0.0179\n",
      "Epoch 54/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9872 - loss: 0.0449 - val_accuracy: 0.9949 - val_loss: 0.0173\n",
      "Epoch 55/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9850 - loss: 0.0505 - val_accuracy: 0.9954 - val_loss: 0.0183\n",
      "Epoch 56/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9868 - loss: 0.0444 - val_accuracy: 0.9943 - val_loss: 0.0168\n",
      "Epoch 57/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9863 - loss: 0.0451 - val_accuracy: 0.9938 - val_loss: 0.0200\n",
      "Epoch 58/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 49ms/step - accuracy: 0.9852 - loss: 0.0489 - val_accuracy: 0.9955 - val_loss: 0.0167\n",
      "Epoch 59/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9874 - loss: 0.0434 - val_accuracy: 0.9945 - val_loss: 0.0165\n",
      "Epoch 60/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9845 - loss: 0.0470 - val_accuracy: 0.9948 - val_loss: 0.0171\n",
      "Epoch 61/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9867 - loss: 0.0436 - val_accuracy: 0.9943 - val_loss: 0.0196\n",
      "Epoch 62/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9861 - loss: 0.0466 - val_accuracy: 0.9954 - val_loss: 0.0159\n",
      "Epoch 63/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 49ms/step - accuracy: 0.9866 - loss: 0.0451 - val_accuracy: 0.9952 - val_loss: 0.0156\n",
      "Epoch 64/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9863 - loss: 0.0435 - val_accuracy: 0.9954 - val_loss: 0.0154\n",
      "Epoch 65/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9874 - loss: 0.0429 - val_accuracy: 0.9955 - val_loss: 0.0141\n",
      "Epoch 66/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9873 - loss: 0.0408 - val_accuracy: 0.9945 - val_loss: 0.0174\n",
      "Epoch 67/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9854 - loss: 0.0472 - val_accuracy: 0.9950 - val_loss: 0.0152\n",
      "Epoch 68/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9875 - loss: 0.0426 - val_accuracy: 0.9950 - val_loss: 0.0145\n",
      "Epoch 69/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9868 - loss: 0.0459 - val_accuracy: 0.9946 - val_loss: 0.0157\n",
      "Epoch 70/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9866 - loss: 0.0445 - val_accuracy: 0.9951 - val_loss: 0.0167\n",
      "Epoch 71/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9875 - loss: 0.0397 - val_accuracy: 0.9936 - val_loss: 0.0209\n",
      "Epoch 72/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9864 - loss: 0.0435 - val_accuracy: 0.9951 - val_loss: 0.0171\n",
      "Epoch 73/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9881 - loss: 0.0396 - val_accuracy: 0.9945 - val_loss: 0.0174\n",
      "Epoch 74/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9873 - loss: 0.0407 - val_accuracy: 0.9946 - val_loss: 0.0170\n",
      "Epoch 75/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9871 - loss: 0.0403 - val_accuracy: 0.9938 - val_loss: 0.0185\n",
      "Epoch 76/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9869 - loss: 0.0423 - val_accuracy: 0.9950 - val_loss: 0.0177\n",
      "Epoch 77/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9873 - loss: 0.0421 - val_accuracy: 0.9944 - val_loss: 0.0185\n",
      "Epoch 78/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9869 - loss: 0.0433 - val_accuracy: 0.9948 - val_loss: 0.0161\n",
      "Epoch 79/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9873 - loss: 0.0395 - val_accuracy: 0.9949 - val_loss: 0.0173\n",
      "Epoch 80/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9868 - loss: 0.0435 - val_accuracy: 0.9948 - val_loss: 0.0178\n",
      "Epoch 81/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9870 - loss: 0.0422 - val_accuracy: 0.9957 - val_loss: 0.0159\n",
      "Epoch 82/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9879 - loss: 0.0405 - val_accuracy: 0.9949 - val_loss: 0.0159\n",
      "Epoch 83/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9888 - loss: 0.0402 - val_accuracy: 0.9946 - val_loss: 0.0156\n",
      "Epoch 84/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9880 - loss: 0.0391 - val_accuracy: 0.9945 - val_loss: 0.0151\n",
      "Epoch 85/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9878 - loss: 0.0387 - val_accuracy: 0.9949 - val_loss: 0.0167\n",
      "Epoch 86/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9893 - loss: 0.0339 - val_accuracy: 0.9944 - val_loss: 0.0195\n",
      "Epoch 87/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 49ms/step - accuracy: 0.9892 - loss: 0.0367 - val_accuracy: 0.9949 - val_loss: 0.0168\n",
      "Epoch 88/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9882 - loss: 0.0395 - val_accuracy: 0.9950 - val_loss: 0.0162\n",
      "Epoch 89/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9884 - loss: 0.0382 - val_accuracy: 0.9948 - val_loss: 0.0165\n",
      "Epoch 90/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9885 - loss: 0.0360 - val_accuracy: 0.9943 - val_loss: 0.0182\n",
      "Epoch 91/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9890 - loss: 0.0373 - val_accuracy: 0.9948 - val_loss: 0.0178\n",
      "Epoch 92/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 49ms/step - accuracy: 0.9874 - loss: 0.0395 - val_accuracy: 0.9948 - val_loss: 0.0174\n",
      "Epoch 93/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9893 - loss: 0.0349 - val_accuracy: 0.9952 - val_loss: 0.0166\n",
      "Epoch 94/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 49ms/step - accuracy: 0.9882 - loss: 0.0387 - val_accuracy: 0.9951 - val_loss: 0.0169\n",
      "Epoch 95/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9888 - loss: 0.0378 - val_accuracy: 0.9960 - val_loss: 0.0149\n",
      "Epoch 96/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9887 - loss: 0.0378 - val_accuracy: 0.9960 - val_loss: 0.0151\n",
      "Epoch 97/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9879 - loss: 0.0371 - val_accuracy: 0.9956 - val_loss: 0.0160\n",
      "Epoch 98/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9892 - loss: 0.0343 - val_accuracy: 0.9951 - val_loss: 0.0164\n",
      "Epoch 99/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.9881 - loss: 0.0383 - val_accuracy: 0.9963 - val_loss: 0.0145\n",
      "Epoch 100/100\n",
      "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9894 - loss: 0.0323 - val_accuracy: 0.9949 - val_loss: 0.0172\n",
      "263/263 - 2s - 6ms/step - accuracy: 0.9949 - loss: 0.0172\n",
      "\n",
      "Test accuracy: 0.9948809742927551\n"
     ]
    }
   ],
   "source": [
    "# Reshape the images from 784 to 28x28 and add a channel dimension for grayscale\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "# x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "data_augmentation = preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Use the data augmentation generator in the fit method\n",
    "model.fit(\n",
    "    data_augmentation.flow(x_train, y_train, batch_size=64),\n",
    "    epochs=100,\n",
    "    validation_data=(x_test, y_test)\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"\\nTest accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cc00ed-70e6-418a-95a1-dfed19d4264b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
